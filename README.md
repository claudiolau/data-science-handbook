# data-science-handbook
Curated list of resources to advance your analytics in Data Science. In the right way.

Some links require incognito mode. <img src='https://static-cdn.jtvnw.net/emoticons/v1/25/1.0'/>

## Contents

- [Statistics](#Statistics)
- [Hypothesis Testing](#Hypothesis-Testing)
- [Machine Learning](#Machine-Learning)
- [Timeseries](#Timeseries)
- [Evaluation](#Evaluation)


# Statistics
- [Central Limit Theorem](https://www.freecodecamp.org/news/how-to-visualize-the-central-limit-theorem-in-python-b619f5b00168/#:~:text=The%20Central%20Limit%20Theorem%20states,the%20shape%20of%20the%20population.): Asserts that the sampling distribution of the sample means approaches a normal distribution as the sample size gets larger.
- [Law of Large Numbers](https://levelup.gitconnected.com/large-numbers-and-central-limit-theorem-using-numpy-1c8199ef63b1): According to the law, the average of the results obtained from a large number of trials should be close to the expected value and will tend to become closer to the expected value as more trials are performed.
- [Q-Q plot](https://towardsdatascience.com/q-q-plots-explained-5aa8495426c0): To determine if two data sets come from populations with a common distribution, in most cases whether it forms a Normal Distribution.
- [Bootstrap](https://medium.com/swlh/bootstrap-sampling-using-pythons-numpy-85822d868977): The bootstrap method involves iteratively resampling a dataset with replacement.
- [Jackknife](https://towardsdatascience.com/resampling-methods-for-inference-analysis-e75fecfefcb2): Jackknife resampling technique is based on creating samples by systematically leaving one observation out in the original dataset.
- [Skewness](https://medium.com/dev-genius/skewness-and-kurtosis-in-data-science-aa795ba4b453): Data skewness analysis and transformation techniques to make distribution into normal distrubtion. 
- [Degrees of Freedom](http://sites.utexas.edu/sos/degreesfreedom/): Number of values in the final calculation of a statistic that are free to vary. In short, It represent the number of points of control of a system, model, or calculation.

# Hypothesis-Testing
- [General Testing](https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce): Basic hypothesis Testing.
- [A/B Testing](https://www.analyticsvidhya.com/blog/2020/10/ab-testing-data-science/): A/B testing is a basic randomized control experiment. It is a way to compare the two versions of a variable to find out which performs better in a controlled environment.
- [F-test in regression analysis](https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259): To determine whether a complex model is better than a simpler version of the same model in explaining the variance in the dependent variable.
- [Sharpio-Wilk Test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html): Tests the null hypothesis that the data was drawn from a normal distribution.

# Machine-Learning 
- [Linear Regression](https://towardsdatascience.com/assumptions-of-linear-regression-5d87c347140): Underlying assumptions before using regression.

# Timeseries
- [Cointegration](https://medium.com/ro-data-team-blog/measuring-correlation-ii-cointegration-for-time-series-analysis-f0f5e6f65f5): Synthetic stationary series from a linear combination of two or more non-stationary series.
- [Var Model & LSTM](https://www.youtube.com/watch?v=_vQ0W_qXMxk&feature=youtu.be): Multivariate analysis talk.

# Evaluation
- [Metrics](https://towardsdatascience.com/forecast-kpi-rmse-mae-mape-bias-cdc5703d242d): Understanding criteria for KPI and pitfall of validation metrics. (ie. MAPE, MAE, ... etc.)
- [Probalistic Model Selection](https://stats.stackexchange.com/questions/577/is-there-any-reason-to-prefer-the-aic-or-bic-over-the-other): Differences between AIC or BIC, tradeoff between simple and complex models.
- [Time Series Crossfold valdiation](https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4):Time dependent cross validation.